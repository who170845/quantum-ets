{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["#Import packages\n","\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import os\n","import path\n","\n","import torch\n","import torchvision\n","from torch.utils import data\n","from torchvision import transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data.sampler import SubsetRandomSampler"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["def target_to_oh(target):\n","    NUM_CLASS = 5  # hard code here, can do partial\n","    one_hot = torch.eye(NUM_CLASS)[target]\n","    return one_hot"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["transform_bunch = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5),\n","                                      transforms.RandomVerticalFlip(p=0.5),\n","                                      transforms.ToTensor()])\n","#                                       transforms.Normalize((0.5139, 0.2727, 0.0891), (0.1533, 0.0909, 0.0400))])"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["ds = torchvision.datasets.ImageFolder(\"../archive/gaussian_filtered_images/gaussian_filtered_images\", transform_bunch, target_transform = target_to_oh)"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1., 0., 0., 0., 0.])\n"]}],"source":["for x,y in ds:\n","    print(y)\n","    break"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["percent = 0.2\n","\n","split = int(len(ds) * percent)\n","\n","indices = list(range(len(ds)))"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["732"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["split"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["train_sampler = SubsetRandomSampler(indices[split:])\n","\n","valid_sampler = SubsetRandomSampler(indices[:split])"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["bs = 100\n","\n","dl = data.DataLoader(ds, bs, sampler=train_sampler)\n","\n","valid_dl = data.DataLoader(ds, bs, sampler=valid_sampler)"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([100, 3, 224, 224]) torch.Size([100, 5])\n"]}],"source":["xx = 0\n","yy = 0\n","\n","for x,y in valid_dl:\n","    print(x.shape,y.shape)\n","    xx = x\n","    yy = y\n","    break"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.]])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["yy"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["{'Mild': 0, 'Moderate': 1, 'No_DR': 2, 'Proliferate_DR': 3, 'Severe': 4}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["#looks like something is off... Yup --> We can just transform it at the end\n","ds.class_to_idx"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[],"source":["#Now I'll be making the model! It'll take elements off of nn.Module\n","class cnnmaker(nn.Module):\n","    #Initialization will only take in input channels\n","    def __init__(self, input_channels):\n","        super().__init__()\n","        \n","        #I looked at what the resnet architechture looked like and just implmented the block types (not the residual part just yet)\n","        def block(in_chan):\n","            return nn.Sequential(nn.Conv2d(in_chan, in_chan * 2, 3, 2, 1, padding_mode = \"reflect\"),\n","                                nn.BatchNorm2d(in_chan*2),\n","                                nn.ReLU())\n","        \n","        self.model = nn.Sequential(block(input_channels),\n","                                  block(input_channels*2),\n","                                  block(input_channels*4),\n","                                  block(input_channels*8),\n","                                  block(input_channels*16))\n","        \n","        self.second_model = nn.Sequential(nn.Linear(4704, 500),\n","                                         nn.Dropout(),\n","                                         nn.ReLU(),\n","                                         nn.Linear(500, 100),\n","                                         nn.Dropout(),\n","                                         nn.ReLU(),\n","                                         nn.Linear(100, 5))\n","    #The forward pass when you call it   \n","    def forward(self, images):\n","        pre_proc = self.model(images)\n","#         print(pre_proc.shape)\n","        \n","        formatted = torch.reshape(pre_proc, (images.shape[0], -1))\n","        \n","        return self.second_model(formatted)"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["model = cnnmaker(3)"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["cnnmaker(\n","  (model): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n","      (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (1): Sequential(\n","      (0): Conv2d(6, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n","      (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (2): Sequential(\n","      (0): Conv2d(12, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n","      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (3): Sequential(\n","      (0): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n","      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (4): Sequential(\n","      (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n","      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (second_model): Sequential(\n","    (0): Linear(in_features=4704, out_features=500, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","    (2): ReLU()\n","    (3): Linear(in_features=500, out_features=100, bias=True)\n","    (4): Dropout(p=0.5, inplace=False)\n","    (5): ReLU()\n","    (6): Linear(in_features=100, out_features=5, bias=True)\n","  )\n",")"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2458905\n"]}],"source":["#Look at how many parameters\n","total = 0\n","for param in model.parameters():\n","    if param.requires_grad:\n","        total += param.numel()\n","\n","print(total)"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["loss_func = nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.Adam(model.parameters())"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[],"source":["model = model.to('cpu')\n","loss_func = loss_func.to('cpu')"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[],"source":["def accuracy(preds, target):\n","    correct = (preds == target).float()\n","    accuracy = correct.sum() / len(correct)\n","    return accuracy"]},{"cell_type":"code","execution_count":30,"metadata":{"trusted":true},"outputs":[],"source":["def train():\n","    model.train()\n","    \n","    for image, label in dl:\n","        image, label = image.type(dtype=torch.FloatTensor), label.type(dtype=torch.FloatTensor)\n","        optimizer.zero_grad()\n","        prediction = model(image)\n","        \n","        loss = loss_func(prediction, label)\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","    \n","    with torch.no_grad():\n","        total_iter = 0\n","        total_acc = 0\n","        for image, label in valid_dl: \n","            image, label = image.to('cpu', dtype=torch.float), label.to('cpu', dtype=torch.float)\n","            prediction = model(image)\n","            total_acc += accuracy(torch.argmax(prediction, dim = 1).float(), torch.argmax(label, dim = 1).float())\n","            total_iter += 1\n","            if total_iter == 7:\n","                print(\"valid\",total_acc/total_iter)\n","                total_iter = 0\n","                total_acc = 0\n","                for image, label in dl: \n","                    image, label = image.to('cpu', dtype=torch.float), label.to('cpu', dtype=torch.float)\n","                    prediction = model(image)\n","                    total_acc += accuracy(torch.argmax(prediction, dim = 1).float(), torch.argmax(label, dim = 1).float())\n","                    total_iter += 1\n","                    if total_iter == 7:\n","                        print(total_acc/total_iter)\n","                        return \"done\""]},{"cell_type":"code","execution_count":31,"metadata":{"trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr = 0.003)"]},{"cell_type":"code","execution_count":32,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["valid tensor(0.1914)\n","tensor(0.7314)\n","valid tensor(0.2957)\n","tensor(0.7886)\n","valid tensor(0.3000)\n","tensor(0.7729)\n","valid tensor(0.2814)\n","tensor(0.7743)\n"]}],"source":["for _ in range(4):\n","    train()"]},{"cell_type":"code","execution_count":33,"metadata":{"trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"]},{"cell_type":"code","execution_count":34,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["valid tensor(0.3714)\n","tensor(0.8057)\n","valid tensor(0.2871)\n","tensor(0.8114)\n","valid tensor(0.3214)\n","tensor(0.7957)\n","valid tensor(0.3400)\n","tensor(0.7957)\n","valid tensor(0.3400)\n","tensor(0.7886)\n","valid tensor(0.3343)\n","tensor(0.7943)\n","valid tensor(0.4057)\n","tensor(0.8014)\n","valid tensor(0.3529)\n","tensor(0.7871)\n","valid tensor(0.3329)\n","tensor(0.8014)\n","valid tensor(0.3657)\n","tensor(0.8100)\n"]}],"source":["for _ in range(10):\n","    train()"]},{"cell_type":"code","execution_count":35,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["valid tensor(0.3171)\n","tensor(0.8043)\n","valid tensor(0.3629)\n","tensor(0.8286)\n","valid tensor(0.3771)\n","tensor(0.8243)\n","valid tensor(0.3929)\n","tensor(0.8071)\n","valid tensor(0.3843)\n","tensor(0.7771)\n","valid tensor(0.3743)\n","tensor(0.8200)\n","valid tensor(0.3886)\n","tensor(0.8071)\n","valid tensor(0.3829)\n","tensor(0.7900)\n","valid tensor(0.3729)\n","tensor(0.8086)\n","valid tensor(0.3929)\n","tensor(0.8029)\n","valid tensor(0.4014)\n","tensor(0.8329)\n","valid tensor(0.3300)\n","tensor(0.8429)\n","valid tensor(0.3600)\n","tensor(0.8229)\n","valid tensor(0.3471)\n","tensor(0.8343)\n","valid tensor(0.3629)\n","tensor(0.8486)\n","valid tensor(0.3629)\n","tensor(0.8386)\n","valid tensor(0.3386)\n","tensor(0.8271)\n","valid tensor(0.3757)\n","tensor(0.8271)\n","valid tensor(0.3571)\n","tensor(0.8400)\n","valid tensor(0.3500)\n","tensor(0.8143)\n"]}],"source":["for _ in range(20):\n","    train()"]},{"cell_type":"code","execution_count":36,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["valid tensor(0.3171)\n","tensor(0.8457)\n","valid tensor(0.3771)\n","tensor(0.8214)\n","valid tensor(0.3457)\n","tensor(0.8643)\n","valid tensor(0.2986)\n","tensor(0.8586)\n","valid tensor(0.3143)\n","tensor(0.8543)\n","valid tensor(0.3571)\n","tensor(0.8814)\n","valid tensor(0.2943)\n","tensor(0.8757)\n","valid tensor(0.3443)\n","tensor(0.8657)\n","valid tensor(0.3114)\n","tensor(0.8700)\n","valid tensor(0.3100)\n","tensor(0.8843)\n","valid tensor(0.3071)\n","tensor(0.8957)\n","valid tensor(0.3171)\n","tensor(0.8900)\n","valid tensor(0.2714)\n","tensor(0.9100)\n","valid tensor(0.2857)\n","tensor(0.9029)\n","valid tensor(0.2929)\n","tensor(0.9129)\n","valid tensor(0.2500)\n","tensor(0.8971)\n","valid tensor(0.2714)\n","tensor(0.8957)\n","valid tensor(0.2943)\n","tensor(0.9129)\n","valid tensor(0.2557)\n","tensor(0.9200)\n","valid tensor(0.3000)\n","tensor(0.9200)\n"]}],"source":["for _ in range(20):\n","    train()"]},{"cell_type":"code","execution_count":37,"metadata":{"trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)"]},{"cell_type":"code","execution_count":38,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["valid tensor(0.2957)\n","tensor(0.9471)\n","valid tensor(0.2843)\n","tensor(0.9500)\n","valid tensor(0.2971)\n","tensor(0.9471)\n","valid tensor(0.3029)\n","tensor(0.9314)\n","valid tensor(0.2686)\n","tensor(0.9529)\n","valid tensor(0.2671)\n","tensor(0.9371)\n","valid tensor(0.2729)\n","tensor(0.9414)\n","valid tensor(0.2700)\n","tensor(0.9400)\n","valid tensor(0.2743)\n","tensor(0.9543)\n","valid tensor(0.2771)\n","tensor(0.9357)\n","valid tensor(0.2943)\n","tensor(0.9714)\n","valid tensor(0.2743)\n","tensor(0.9471)\n","valid tensor(0.2643)\n","tensor(0.9643)\n","valid tensor(0.2800)\n","tensor(0.9614)\n","valid tensor(0.2771)\n","tensor(0.9557)\n","valid tensor(0.2786)\n","tensor(0.9600)\n","valid tensor(0.2786)\n","tensor(0.9514)\n","valid tensor(0.2757)\n","tensor(0.9714)\n","valid tensor(0.2614)\n","tensor(0.9543)\n","valid tensor(0.2771)\n","tensor(0.9671)\n"]}],"source":["for _ in range(20):\n","    train()"]},{"cell_type":"code","execution_count":39,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([100, 3, 224, 224]) torch.Size([100, 5])\n"]}],"source":["xxx = 0\n","yyy = 0\n","\n","for x,y in dl:\n","    print(x.shape,y.shape)\n","    xxx = x\n","    yyy = y\n","    break"]},{"cell_type":"code","execution_count":40,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["tensor([2., 2., 3., 2., 1., 1., 2., 2., 1., 2., 2., 2., 2., 3., 2., 4., 2., 2.,\n","        2., 2., 2., 1., 2., 3., 2., 1., 2., 1., 2., 4., 1., 2., 2., 1., 2., 2.,\n","        2., 2., 4., 4., 1., 2., 2., 2., 2., 2., 2., 2., 1., 1., 2., 1., 2., 2.,\n","        2., 2., 2., 4., 4., 2., 2., 2., 3., 2., 2., 1., 2., 2., 2., 1., 4., 4.,\n","        1., 1., 1., 1., 3., 2., 2., 2., 2., 2., 2., 3., 2., 2., 1., 2., 4., 2.,\n","        2., 3., 2., 2., 2., 2., 3., 2., 1., 1.])"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["yyy = yyy.type(dtype=torch.FloatTensor)\n","torch.argmax(yyy, dim = 1).float()"]},{"cell_type":"code","execution_count":41,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["tensor([2., 2., 3., 2., 1., 3., 2., 2., 1., 2., 2., 2., 2., 3., 2., 4., 2., 2.,\n","        2., 2., 2., 1., 2., 3., 2., 1., 2., 1., 2., 4., 1., 2., 2., 1., 2., 2.,\n","        2., 2., 4., 3., 1., 2., 2., 2., 2., 2., 2., 2., 1., 1., 2., 1., 2., 2.,\n","        2., 2., 2., 4., 1., 2., 2., 2., 3., 2., 2., 1., 2., 2., 2., 1., 4., 4.,\n","        1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 4., 2., 2., 1., 2., 4., 2.,\n","        2., 3., 2., 2., 2., 2., 1., 2., 1., 1.])"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["xxx = xxx.type(dtype=torch.FloatTensor)\n","prediction = model(xxx)\n","torch.argmax(prediction, dim = 1).float()\n"]},{"cell_type":"code","execution_count":42,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["tensor(0.9400)"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["accuracy(torch.argmax(prediction, dim = 1).float(),torch.argmax(yyy, dim = 1).float())"]},{"cell_type":"code","execution_count":43,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(0.9800)\n","tensor(0.9800)\n","tensor(0.9600)\n","tensor(0.9900)\n","tensor(0.9800)\n","tensor(0.9900)\n","tensor(0.9400)\n","tensor(0.9500)\n","tensor(0.9400)\n","tensor(0.9500)\n","tensor(0.9700)\n","tensor(0.9200)\n","tensor(0.9700)\n","tensor(0.9600)\n","tensor(0.9600)\n","tensor(0.9700)\n","tensor(0.9100)\n","tensor(0.9800)\n","tensor(0.9600)\n","tensor(0.9700)\n","tensor(0.9615)\n","tensor(0.9600)\n","tensor(0.9700)\n","tensor(0.9700)\n","tensor(0.9300)\n","tensor(0.9500)\n","tensor(0.9400)\n","tensor(0.9700)\n","tensor(0.9200)\n","tensor(0.9700)\n","tensor(1.)\n"]}],"source":["with torch.no_grad():\n","    total_iter = 0\n","    total_acc = 0\n","    for image, label in dl: \n","        image, label = image.to('cpu', dtype=torch.float), label.to('cpu', dtype=torch.float)\n","        prediction = model(image)\n","        h = accuracy(torch.argmax(prediction, dim = 1).float(), torch.argmax(label, dim = 1).float())\n","        print(h)\n","        total_acc += h\n","        total_iter += 1\n","        if total_iter == 20:\n","            print(total_acc/total_iter)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"3.10.6","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":4}
